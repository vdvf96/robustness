{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1xJm8ON_bUbCrEb7m3-DLBQseP8Tk2tpd",
      "authorship_tag": "ABX9TyO7471//AQimp5Eh9NbrO/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vdvf96/robustness/blob/master/MNIST_SMART_ENSEMBLE_CVXPY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1GsNDbVFNb8b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import argparse\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelectNet(nn.Module):\n",
        "    def __init__(self, n_models):\n",
        "        super(SelectNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 2*n_models)\n",
        "        self.fc2 = nn.Linear(2*n_models, n_models)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = x #F.log_softmax(x, dim=1)   JK try this\n",
        "        return output"
      ],
      "metadata": {
        "id": "3r5C3r_9Ninx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_kwargs = {'batch_size': 32}\n",
        "test_kwargs = {'batch_size': 1000}\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transform)\n",
        "dataset2 = datasets.MNIST('../data', train=False,\n",
        "                       transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset2,**train_kwargs)"
      ],
      "metadata": {
        "id": "Az3dWwF-NllA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.name = 'Net'\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d(p=0.1)\n",
        "        self.fc1 = nn.Linear(320, 32)  # nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(32, 32)\n",
        "        self.fc3 = nn.Linear(32, 10)  # nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "RJ2r00qsNptF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "model = [Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device),\n",
        "           Net().to(device),Net().to(device),Net().to(device),Net().to(device),Net().to(device)]"
      ],
      "metadata": {
        "id": "VbjiYQ9YNtJh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJcuc4NcNvo8",
        "outputId": "50eeba73-a7f9-4876-8634-3470620b2d2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSilZfQeNVmE",
        "outputId": "d2148f3d-3b8b-4bac-8abd-a58fddb0127f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "path='drive/MyDrive/MNIST_spec_models'\n",
        "model[0].load_state_dict(torch.load(path+'/model_0',map_location=torch.device('cpu')))\n",
        "model[1].load_state_dict(torch.load(path+'/model_1',map_location=torch.device('cpu')))\n",
        "model[2].load_state_dict(torch.load(path+'/model_2',map_location=torch.device('cpu')))\n",
        "model[3].load_state_dict(torch.load(path+'/model_3',map_location=torch.device('cpu')))\n",
        "model[4].load_state_dict(torch.load(path+'/model_4',map_location=torch.device('cpu')))\n",
        "model[5].load_state_dict(torch.load(path+'/model_5',map_location=torch.device('cpu')))\n",
        "model[6].load_state_dict(torch.load(path+'/model_6',map_location=torch.device('cpu')))\n",
        "model[7].load_state_dict(torch.load(path+'/model_7',map_location=torch.device('cpu')))\n",
        "model[8].load_state_dict(torch.load(path+'/model_8',map_location=torch.device('cpu')))\n",
        "model[9].load_state_dict(torch.load(path+'/model_9',map_location=torch.device('cpu')))\n",
        "model[10].load_state_dict(torch.load(path+'/model_10',map_location=torch.device('cpu')))\n",
        "model[11].load_state_dict(torch.load(path+'/model_12',map_location=torch.device('cpu')))\n",
        "model[12].load_state_dict(torch.load(path+'/model_13',map_location=torch.device('cpu')))\n",
        "model[13].load_state_dict(torch.load(path+'/model_14',map_location=torch.device('cpu')))\n",
        "model[14].load_state_dict(torch.load(path+'/model_15',map_location=torch.device('cpu')))\n",
        "model[15].load_state_dict(torch.load(path+'/model_16',map_location=torch.device('cpu')))\n",
        "model[16].load_state_dict(torch.load(path+'/model_17',map_location=torch.device('cpu')))\n",
        "model[17].load_state_dict(torch.load(path+'/model_18',map_location=torch.device('cpu')))\n",
        "model[18].load_state_dict(torch.load(path+'/model_19',map_location=torch.device('cpu')))\n",
        "model[19].load_state_dict(torch.load(path+'/model_20',map_location=torch.device('cpu')))\n",
        "model[20].load_state_dict(torch.load(path+'/model_23',map_location=torch.device('cpu')))\n",
        "model[21].load_state_dict(torch.load(path+'/model_24',map_location=torch.device('cpu')))\n",
        "model[22].load_state_dict(torch.load(path+'/model_25',map_location=torch.device('cpu')))\n",
        "model[23].load_state_dict(torch.load(path+'/model_26',map_location=torch.device('cpu')))\n",
        "model[24].load_state_dict(torch.load(path+'/model_27',map_location=torch.device('cpu')))\n",
        "model[25].load_state_dict(torch.load(path+'/model_28',map_location=torch.device('cpu')))\n",
        "model[26].load_state_dict(torch.load(path+'/model_29',map_location=torch.device('cpu')))\n",
        "model[27].load_state_dict(torch.load(path+'/model_30',map_location=torch.device('cpu')))\n",
        "model[28].load_state_dict(torch.load(path+'/model_34',map_location=torch.device('cpu')))\n",
        "model[29].load_state_dict(torch.load(path+'/model_35',map_location=torch.device('cpu')))\n",
        "model[30].load_state_dict(torch.load(path+'/model_36',map_location=torch.device('cpu')))\n",
        "model[31].load_state_dict(torch.load(path+'/model_37',map_location=torch.device('cpu')))\n",
        "model[32].load_state_dict(torch.load(path+'/model_38',map_location=torch.device('cpu')))\n",
        "model[33].load_state_dict(torch.load(path+'/model_39',map_location=torch.device('cpu')))\n",
        "model[34].load_state_dict(torch.load(path+'/model_40',map_location=torch.device('cpu')))\n",
        "model[35].load_state_dict(torch.load(path+'/model_45',map_location=torch.device('cpu')))\n",
        "model[36].load_state_dict(torch.load(path+'/model_46',map_location=torch.device('cpu')))\n",
        "model[37].load_state_dict(torch.load(path+'/model_47',map_location=torch.device('cpu')))\n",
        "model[38].load_state_dict(torch.load(path+'/model_48',map_location=torch.device('cpu')))\n",
        "model[39].load_state_dict(torch.load(path+'/model_49',map_location=torch.device('cpu')))\n",
        "model[40].load_state_dict(torch.load(path+'/model_50',map_location=torch.device('cpu')))\n",
        "model[41].load_state_dict(torch.load(path+'/model_56',map_location=torch.device('cpu')))\n",
        "model[42].load_state_dict(torch.load(path+'/model_57',map_location=torch.device('cpu')))\n",
        "model[43].load_state_dict(torch.load(path+'/model_58',map_location=torch.device('cpu')))\n",
        "model[44].load_state_dict(torch.load(path+'/model_59',map_location=torch.device('cpu')))\n",
        "model[45].load_state_dict(torch.load(path+'/model_60',map_location=torch.device('cpu')))\n",
        "model[46].load_state_dict(torch.load(path+'/model_67',map_location=torch.device('cpu')))\n",
        "model[47].load_state_dict(torch.load(path+'/model_68',map_location=torch.device('cpu')))\n",
        "model[48].load_state_dict(torch.load(path+'/model_69',map_location=torch.device('cpu')))\n",
        "model[49].load_state_dict(torch.load(path+'/model_70',map_location=torch.device('cpu')))\n",
        "model[50].load_state_dict(torch.load(path+'/model_78',map_location=torch.device('cpu')))\n",
        "model[51].load_state_dict(torch.load(path+'/model_79',map_location=torch.device('cpu')))\n",
        "model[52].load_state_dict(torch.load(path+'/model_80',map_location=torch.device('cpu')))\n",
        "model[53].load_state_dict(torch.load(path+'/model_89',map_location=torch.device('cpu')))\n",
        "model[54].load_state_dict(torch.load(path+'/model_90',map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cvxpy as cp\n",
        "import cvxpylayer"
      ],
      "metadata": {
        "id": "BiojSpedPZdn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cvxpylayer import CvxpyLayer"
      ],
      "metadata": {
        "id": "ZJhGB90HwCLZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_models = len(model)  # how many models in the overall / initial ensemble\n",
        "for i in range(n_models):\n",
        "    for param in model[i].parameters():\n",
        "        param.requires_grad_(False)\n",
        "selection_net = SelectNet(n_models).to(device)\n",
        "\n",
        "params=selection_net.parameters()\n",
        "\n",
        "#loss_fun = utils.HammingLoss()\n",
        "loss_fun = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adadelta(params)\n",
        "#optimizer = optim.SGD(params, lr=0.001, momentum=0.9)\n",
        "#for i in range (args.epochs):\n",
        "train_data, test_data = [], []\n",
        "for i in range (55):\n",
        "  print(i+1)\n",
        "  print(\"TRAINING\")\n",
        "  train_avg = []\n",
        "  train_selection(selection_net, model, device, train_loader,optimizer,i+1,loss_fun, train_avg)\n",
        "  train_data.append(train_avg)\n",
        "      #scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "  print(\"TEST\")\n",
        "  test_avg = []\n",
        "  test(selection_net, model, device, test_loader,i+1,test_avg)\n",
        "  test_data.append(test_avg)\n",
        "\n",
        "  with open('test.txt', 'w') as fp:\n",
        "      fp.write(str(i+1)+\"\\n\")\n",
        "      for item in test_avg:\n",
        "          # write each item on a new line\n",
        "          fp.write(str(item)+\"\\n\")\n",
        "          \n",
        "  with open(r'train.txt', 'w') as fp:\n",
        "      fp.write(str(i+1)+\"\\n\")\n",
        "      for item in train_avg:\n",
        "          # write each item on a new line\n",
        "          fp.write(str(item)+\"\\n\")"
      ],
      "metadata": {
        "id": "PUKHlDqpJdA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece58fe5-b454-4d18-a343-a101fd997fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "TRAINING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2981.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function value: \n",
            "0.05391145497560501\n",
            "Accuracy per batch size: \n",
            "0.96875\n",
            "Average accuracy: \n",
            "0.9340625\n",
            "Loss function value: \n",
            "0.06385114043951035\n",
            "Accuracy per batch size: \n",
            "0.96875\n",
            "Average accuracy: \n",
            "0.93296875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_selection(selection_net,model, device, train_loader, optimizer, c, loss_fun, avg):\n",
        "    n_models = len(model)  # how many models in the overall / initial ensemble\n",
        "    for m in model:\n",
        "        m.eval()\n",
        "    # This will predict the activations used to make a model selection\n",
        "\n",
        "    C = c # how many models should be selected among n_models\n",
        "\n",
        "    # simple unweighted knapsack solver, chooses C items with the largest scores\n",
        "    # output is 0-1 vector where the 1's indicate chosen items\n",
        "    def batch_knapsack(scores): #64000*55\n",
        "        indices = torch.topk(scores, C).indices #64000*21\n",
        "        choice = torch.zeros_like( scores )\n",
        "\n",
        "        choice.scatter_(1,indices,torch.ones(indices.shape,device=device))\n",
        "        return choice\n",
        "    # A 'differentiable' knapsack solver\n",
        "    # See Berthet et al. 'Learning with Differentiable Perturbed Optimizers'\n",
        "    # The parameters to this function may need adjusting\n",
        "    x = cp.Variable(n_models)\n",
        "    c = cp.Parameter(n_models)\n",
        "    eps = 0.5\n",
        "    constraints = [cp.sum(x) == C, x >= 0]\n",
        "    problem = cp.Problem(cp.Maximize(c @ x - eps * cp.norm(x, p=2)), constraints)\n",
        "    assert problem.is_dpp()\n",
        "    knapsack_layer = CvxpyLayer(problem, parameters=[c], variables=[x])\n",
        "\n",
        "    error = 0\n",
        "    total = 0\n",
        "    #random_total = 0\n",
        "    nIm = 0\n",
        "    #total_correct_dump_pred = 0\n",
        "    iteration = 1\n",
        "    #total_correct_unselected_predictions = 0\n",
        "    correct_array = []\n",
        "    total_dumb_calls = 0\n",
        "    dumb_calls_array = []\n",
        "\n",
        "    for e in range(1):\n",
        "        for data, target in train_loader:\n",
        "\n",
        "            data, target = data.to(device), target.to(device)\n",
        "        # probably not perfect wrt tensor orientation\n",
        "            dim = target.shape[0]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            predictions = torch.stack( [m(data) for m in model] ) #n_models*batch_size*10   #majority_voter(model,data)\n",
        "            selection_vals = selection_net(data) #batch_size*n_models\n",
        "\n",
        "            continuous_selections = knapsack_layer(selection_vals)[0]\n",
        "\n",
        "            selections = batch_knapsack(continuous_selections)\n",
        "            \n",
        "            selection_vals = torch.nn.functional.normalize(selection_vals)\n",
        "\n",
        "            selections = selections.repeat(10,1,1).T #n_models*batch_size*10\n",
        "\n",
        "            predictions = predictions * selections * selection_vals.repeat(10,1,1).T\n",
        "\n",
        "            ensemble_pred = torch.zeros((dim,10))\n",
        "\n",
        "            ensemble_pred = ensemble_pred.to(device)\n",
        "\n",
        "\n",
        "            for i in predictions:   # batch_size*10\n",
        "                ensemble_pred += i\n",
        "\n",
        "            #majority_pred = torch.softmax(ensemble_pred,1)\n",
        "\n",
        "            binary_target = torch.zeros((dim,10))\n",
        "\n",
        "            binary_target = binary_target.to(device)\n",
        "\n",
        "            index = 0\n",
        "\n",
        "            for t in target:\n",
        "                binary_target[index,t.item()]=1\n",
        "                index += 1\n",
        "\n",
        "            loss = loss_fun(ensemble_pred,binary_target)\n",
        "            \n",
        "\n",
        "            index=0\n",
        "            correct = 0\n",
        "\n",
        "            app = binary_target.cpu().detach().numpy()\n",
        "            app2 = ensemble_pred.cpu().detach().numpy()\n",
        "\n",
        "            for i in range(dim):\n",
        "                t_max_index = np.argmax(app[i,:])\n",
        "                p_max_index = np.argmax(app2[i,:])\n",
        "                if(t_max_index == p_max_index):\n",
        "                    correct += 1\n",
        "\n",
        "            total += correct\n",
        "            nIm += dim\n",
        "\n",
        "        # Choose a suitable loss function that compares the 'majority' prediction\n",
        "        # to the labeled target one-hot. Note that both are 'hard' predictions,\n",
        "        # being 0-1 and not softmax values. Try a simple dot product or Hamming distance.\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (iteration%100==0):\n",
        "              print(\"Loss function value: \")\n",
        "              print(str(loss.item()))\n",
        "              print(\"Accuracy per batch size: \")\n",
        "              print(str(correct/dim))\n",
        "              print(\"Average accuracy: \")\n",
        "              print(str(total/nIm))\n",
        "              avg.append(total/nIm)\n",
        "        #print(\"Random selection average accuracy: \", random_total/nIm)\n",
        "        #print(\"Average of dumb calls :\",total_dumb_calls/2/nIm)\n",
        "\n",
        "        #print(\"Dumb calls per batch size: \",dumb_calls)\n",
        "\n",
        "        #print(\"Correct dumb predictions per batch size: \", exact_dumb_pred)\n",
        "        #print(\"Average correct dumb predictions: \", total_correct_dump_pred/iteration)\n",
        "        #print(\"Percentage of correct unselected predictions: \",correct_unselected_predictions/(64*(n_models-C)))\n",
        "        #print(\"Average percentage of correct unselected predictions: \",total_correct_unselected_predictions/(64*(n_models-C))/iteration)\n",
        "\n",
        "\n",
        "            iteration += 1\n",
        "            "
      ],
      "metadata": {
        "id": "kBbZ5xECJmqg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(selection_net, age_model, device, test_loader,c,avg):\n",
        "    #model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    C = c\n",
        "    def batch_knapsack(scores): #64000*55\n",
        "        indices = torch.topk(scores, C).indices #64000*21\n",
        "        choice = torch.zeros_like( scores )\n",
        "\n",
        "        #somma = torch.sum(scores(1,))\n",
        "\n",
        "\n",
        "        choice.scatter_(1,indices,torch.ones(indices.shape,device=device))\n",
        "        return choice\n",
        "\n",
        "    x = cp.Variable(n_models)\n",
        "    c = cp.Parameter(n_models)\n",
        "    eps = 0.5\n",
        "    constraints = [cp.sum(x) == C, x >= 0]\n",
        "    problem = cp.Problem(cp.Maximize(c @ x - eps * cp.norm(x, p=2)), constraints)\n",
        "    assert problem.is_dpp()\n",
        "    knapsack_layer = CvxpyLayer(problem, parameters=[c], variables=[x])\n",
        "    \n",
        "    correct, total, p_correct, p_total, nIm = 0, 0, 0, 0, 0\n",
        "    iteration = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # probably not perfect wrt tensor orientation\n",
        "            dim = target.shape[0]\n",
        "            age_predictions = torch.zeros(len(age_model), dim, 10)\n",
        "            # gender_predictions = torch.zeros(len(age_model), dim, 2)\n",
        "            # race_predictions = torch.zeros(len(age_model), dim, 5)\n",
        "\n",
        "            age_predictions = torch.stack([m(data) for m in\n",
        "                                           age_model])  # n_models*batch_size*_classes   #majority_voter(model,data)\n",
        "            # gender_predictions = torch.stack( [m(data) for m in gender_model] )\n",
        "            # race_predictions = torch.stack( [m(data) for m in race_model] )\n",
        "            selection_vals = selection_net(data)  # batch_size*n_models\n",
        "            # selection_vals.requires_grad_()\n",
        "            \n",
        "            #selection_vals = torch.nn.Relu(selection_vals)\n",
        "            continuous_selections = knapsack_layer(selection_vals)[0]\n",
        "\n",
        "            selection_vals = torch.nn.functional.normalize(selection_vals)\n",
        "\n",
        "            selections = batch_knapsack(continuous_selections)\n",
        "\n",
        "            #selection_vals = torch.nn.functional.normalize(selection_vals)  # before I applied L2 normalization - torch.nn.functional.normalize(selection_vals)\n",
        "            age_predictions = age_predictions * selections.repeat(10, 1, 1).T * \\\n",
        "                              selection_vals.repeat(10, 1, 1).T\n",
        "\n",
        "            age_majority_pred = torch.zeros((dim,10))\n",
        "\n",
        "            age_majority_pred = age_majority_pred.to(device)\n",
        "\n",
        "            for i in age_predictions:   # batch_size*10\n",
        "                age_majority_pred += i\n",
        "\n",
        "            age_binary_target = torch.zeros((dim, 10))\n",
        "\n",
        "            age_binary_target = age_binary_target.to(device)\n",
        "\n",
        "            index = 0\n",
        "            p = 0\n",
        "            for t in target:\n",
        "                age_binary_target[index, t.item()] = 1\n",
        "                index += 1\n",
        "\n",
        "\n",
        "            index = 0\n",
        "            age_correct = 0\n",
        "\n",
        "            for b in age_binary_target:\n",
        "\n",
        "                a = torch.argmax(b)\n",
        "                pred = torch.argmax(age_majority_pred[index, :])\n",
        "\n",
        "                if (a == pred):\n",
        "                    age_correct += 1\n",
        "                index += 1\n",
        "\n",
        "            total += age_correct  # + gender_correct + race_correct\n",
        "\n",
        "            nIm += dim\n",
        "            # print(\"Gender accuracy: \",gender_correct/dim)\n",
        "            #print(\"Age accuracy: \")\n",
        "            #print(str(age_correct / dim))\n",
        "            # print(\"Race accuracy: \",race_correct/dim)\n",
        "            # print(\"Accuracy per batch size: \",(age_correct+gender_correct+race_correct)/(3*dim))\n",
        "            print(\"Average accuracy: \")\n",
        "            print(str(total / (nIm)))\n",
        "            avg.append(str(total / (nIm)))"
      ],
      "metadata": {
        "id": "mObAUP_uJiAD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffcp==1.0.19  "
      ],
      "metadata": {
        "id": "X0Ih7UQbJi2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f6d2809-cd7b-448d-d4db-33be68dd9cb3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting diffcp==1.0.19\n",
            "  Downloading diffcp-1.0.19-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 15.3 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.4\n",
            "  Downloading pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 75.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from diffcp==1.0.19) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=1.1 in /usr/local/lib/python3.7/dist-packages (from diffcp==1.0.19) (3.1.0)\n",
            "Requirement already satisfied: ecos in /usr/local/lib/python3.7/dist-packages (from diffcp==1.0.19) (2.0.10)\n",
            "Requirement already satisfied: scs>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from diffcp==1.0.19) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from diffcp==1.0.19) (1.7.3)\n",
            "Installing collected packages: pybind11, diffcp\n",
            "Successfully installed diffcp-1.0.19 pybind11-2.10.0\n"
          ]
        }
      ]
    }
  ]
}